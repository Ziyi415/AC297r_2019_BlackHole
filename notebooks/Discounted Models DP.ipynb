{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')## Import Data## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the baseline model, we calculate the reward function for each telescope on each day using $$f(D, R) = -\\frac{1}{T(R)}\\sum_{t = 1}^{T(R)}{\\tau_{225}(D, t)},$$ where $D$ is the date we are looking at for the weather forecast, $R$ refers to the specific telescope, and $T(R)$ is the number of times forecasts being made in the telescope's observation timeframe. For each day, we calculate the day's reward by combining the telescopes' rewards in weighted average. $$F(D) = \\sum_{i = 1}^N{W_{R_i}\\times f(D, R_i)}.$$ Then we make decisions on whether to trigger the day based on the pure values of $F(D)$.\n",
    "\n",
    "In the discounted model, we calculate $$F(D, r) = {\\sum_{i = 1}^N{W_{R_i}\\times f(D, R_i)}}\\times{(1+r)^D},$$ where $r$ is the discount factor and then make decisions on $F(D,r)$. We multiply rather than divide here because the value is negative. We are going to experiment with different fixed value of $r$, and a function of $r$ depending on the variances in the forecasts, and compare the results with the ground-truth optimal path.\n",
    "\n",
    "We also experimented with different weights. In the baseline model, we were using the output  file size as a measure of how important each telescope is. In the discounted model, we adjusted the weights by using the area of the telescope. We further scaled all $F(D, r)$ to be a weighted average of $f(D, R_i)$, by letting $W_{R_i}$ be the proportion of telescope $R_i$'s area in the total area. By doing this, we think the output can be more interpretable.\n",
    "\n",
    "When we do evaluations, we are essentially looking backwards. Therefore, we directly calculate the scores without the discount factor $r$, for both the ground-truth path and our suggested path. The score given to any path $P$ is going to be $$S(P) = \\frac{2}{1 + e^{- \\sum_{j=1}^{\\text{Days}}{F(D_{P,j})}}},$$ where $D_{P,j}$ is the $j$-th day selected by the path $P$. We have $2$ in the numerator, because the sigmoid function will give us values from 0 to 0.5 based on our negative $F$ values and we want to get scores from 0 to 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "telescopes = ['12-meter','alma','apex','aste','iram','jcmt','lmt','sma','smt','spt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = datetime(2019,10,3,6)\n",
    "endtime = datetime(2019,10,14,0) # not included\n",
    "timestamps = np.arange(starttime, endtime, \n",
    "                       timedelta(hours=6)).astype(datetime)\n",
    "databook = {}\n",
    "for ts in telescopes:\n",
    "    databook[ts] = dict.fromkeys(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ts in telescopes:\n",
    "#     for t in timestamps:\n",
    "#         filepath = \"data/\"+ ts +\"/\"+ t.strftime(\"%Y%m%d_%H:%M:%S\")\n",
    "#         try:\n",
    "#             df = pd.read_csv(filepath, delim_whitespace=True, skiprows = 1, header = None)\n",
    "#             df.columns = [\"date\", \"tau225\", \"Tb[k]\", \"pwv[mm]\", \"lwp[kg*m^-2]\",\"iwp[kg*m^-2]\",\"o3[DU]\"]\n",
    "#             df['date'] = pd.to_datetime(df['date'], format = \"%Y%m%d_%H:%M:%S\")\n",
    "#             databook[ts][t] = df\n",
    "#         except FileNotFoundError:\n",
    "#             databook[ts][t] = None\n",
    "# # databook is a dictionary of dictionaries of dataframes \n",
    "# # keys: telescope names\n",
    "# # values: dictionaries of dataframes for one telescope\n",
    "# # databook[telescope_name] is a dictionary of dataframes for one telescope\n",
    "# # keys: timestamps when the forecast is made\n",
    "# # values: forecast dataframe (None if missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## fake data ###################\n",
    "actual_time_span = np.arange(datetime(2019,7,1,0), datetime(2019,10,22,6), \n",
    "                       timedelta(hours=6)).astype(datetime)\n",
    "\n",
    "i = 0\n",
    "for site in telescopes:\n",
    "    for t in timestamps:\n",
    "        actual_time = actual_time_span[i]\n",
    "        time_delta = t - actual_time\n",
    "        filepath = \"data/MaunaKea/\"+ actual_time.strftime(\"%Y%m%d_%H:%M:%S\")\n",
    "        df = pd.read_csv(filepath, delim_whitespace=True, skiprows = 1, header = None)\n",
    "        df.columns = [\"date\", \"tau225\", \"Tb[k]\", \"pwv[mm]\", \"lwp[kg*m^-2]\",\"iwp[kg*m^-2]\",\"o3[DU]\"]\n",
    "        df['date'] = pd.to_datetime(df['date'], format = \"%Y%m%d_%H:%M:%S\") + time_delta\n",
    "        databook[site][t] = df\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12-meter 2019-10-03 12:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tau225</th>\n",
       "      <th>Tb[k]</th>\n",
       "      <th>pwv[mm]</th>\n",
       "      <th>lwp[kg*m^-2]</th>\n",
       "      <th>iwp[kg*m^-2]</th>\n",
       "      <th>o3[DU]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-03 12:00:00</td>\n",
       "      <td>0.14078</td>\n",
       "      <td>39.414</td>\n",
       "      <td>3.2865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-03 13:00:00</td>\n",
       "      <td>0.14125</td>\n",
       "      <td>39.575</td>\n",
       "      <td>3.2760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-10-03 14:00:00</td>\n",
       "      <td>0.14093</td>\n",
       "      <td>39.556</td>\n",
       "      <td>3.2474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>265.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-03 15:00:00</td>\n",
       "      <td>0.13977</td>\n",
       "      <td>39.343</td>\n",
       "      <td>3.2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>265.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-10-03 16:00:00</td>\n",
       "      <td>0.13965</td>\n",
       "      <td>39.350</td>\n",
       "      <td>3.1803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>266.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date   tau225   Tb[k]  pwv[mm]  lwp[kg*m^-2]  iwp[kg*m^-2]  \\\n",
       "0 2019-10-03 12:00:00  0.14078  39.414   3.2865           0.0           0.0   \n",
       "1 2019-10-03 13:00:00  0.14125  39.575   3.2760           0.0           0.0   \n",
       "2 2019-10-03 14:00:00  0.14093  39.556   3.2474           0.0           0.0   \n",
       "3 2019-10-03 15:00:00  0.13977  39.343   3.2021           0.0           0.0   \n",
       "4 2019-10-03 16:00:00  0.13965  39.350   3.1803           0.0           0.0   \n",
       "\n",
       "   o3[DU]  \n",
       "0  264.41  \n",
       "1  264.04  \n",
       "2  265.37  \n",
       "3  265.87  \n",
       "4  266.10  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(telescopes[0],timestamps[1])\n",
    "(databook[telescopes[0]][timestamps[1]]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_reward(telescope_name, day_current_str, end_day_str, start_time, end_time, \\\n",
    "            use_as_evaluate = False):\n",
    "    '''\n",
    "    For the specified telescope, return a dataframe with two columns.\n",
    "    The first column tells the day in the day window between \n",
    "        day_current_str and end_day_str (inclusive).\n",
    "    The second column tells the average predicted tao225 given the day and the time window between\n",
    "        start_time and end_time (inclusive).\n",
    "    \n",
    "    '''\n",
    "    split_day_current = day_current_str.split('-')\n",
    "    split_day_end = end_day_str.split('-') # include this day\n",
    "    \n",
    "    day_current = datetime(int(split_day_current[0]),int(split_day_current[1]),int(split_day_current[2]),0)\n",
    "    day_end = datetime(int(split_day_end[0]),int(split_day_end[1]),int(split_day_end[2])+1,0)\n",
    "    \n",
    "    if not use_as_evaluate:\n",
    "        mask = [t < day_current for t in databook[telescope_name]]\n",
    "        t_valid = np.array([t for t in databook[telescope_name]])[mask]\n",
    "\n",
    "        df_all = pd.concat([databook[telescope_name][t] for t in t_valid], axis =0)\n",
    "    else:\n",
    "        df_all = pd.concat([databook[telescope_name][t] for t in databook[telescope_name]], axis =0)\n",
    "        \n",
    "    df_tau_all = df_all.groupby('date').agg({'tau225':lambda x: list(x)}).reset_index()\n",
    "    \n",
    "    df_tau_all['latest'] = df_tau_all['tau225'].apply(lambda x: x[-1]) # baseline only use \n",
    "    \n",
    "    \n",
    "    df_tau_all = df_tau_all[(df_tau_all.date >= day_current) & (df_tau_all.date < day_end)]\n",
    "    \n",
    "    \n",
    "    # calculate the reward for each day based on the schedule\n",
    "    df_tau_all['day'] = df_tau_all.date.apply(lambda x: str(x).split(' ')[0])\n",
    "    df_tau_all['time'] = df_tau_all.date.apply(lambda x: int(str(x).split(' ')[1][0:2]))\n",
    "    \n",
    "    df_tau_all = df_tau_all[(df_tau_all.time >= int(start_time)) & (df_tau_all.time <= int(end_time))]\n",
    "    df_tau_day = pd.DataFrame(-df_tau_all.groupby('day')['latest'].mean())\n",
    "    \n",
    "    return df_tau_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Weighted sum the reward for each telescope according to the total Gbytes.** \n",
    "(so far we have not taken the telescopes '12-meter','aste','iram' into account as we haven't found corresponding schedule and weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight_telescope = [0, 22830.7, 26153.8, 0, 0, 12123.0, 22215.3, 12123.0, 18030.7, 26953.8]\n",
    "\n",
    "# using the area (radius ** 2) of the telescope as weights \n",
    "weight_telescope = [12**2, 73**2, 12**2, 10**2, 30**2, 15**2, 32.5**2, 14.7**2, 10**2, 6**2]\n",
    "schedule_telescope = [[0,1], [3,13], [3,15], [0,1], [0,1], [10,16], [6,16], [10,16], [8,16], [3,15]]\n",
    "\n",
    "\n",
    "dict_schedule = dict(zip(telescopes, schedule_telescope))\n",
    "dict_weight = dict(zip(telescopes, weight_telescope))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_day_reward(day_current_str, end_day_str):\n",
    "    \"\"\"\n",
    "    calculate F(D) for D in range(day_current_str, end_day_str)\n",
    "    taking in every single telescope we currently have\n",
    "    weighted their f reward values\n",
    "    based on area_i/total_area\n",
    "    \"\"\"\n",
    "    # set up a dataframe\n",
    "    telescopes_day_reward = day_reward(telescopes[0], day_current_str, end_day_str, \\\n",
    "                                       dict_schedule[telescopes[0]][0], dict_schedule[telescopes[0]][1]) \\\n",
    "                                       * dict_weight[telescopes[0]] \n",
    "    # \n",
    "    for i in telescopes[1:]:\n",
    "        telescopes_day_reward += day_reward(i, day_current_str, end_day_str, \\\n",
    "                                            dict_schedule[i][0], dict_schedule[i][1])\\\n",
    "                                            * dict_weight[i] \n",
    "    return telescopes_day_reward / sum(weight_telescope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-05</th>\n",
       "      <td>-0.141922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-06</th>\n",
       "      <td>-0.123334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-07</th>\n",
       "      <td>-0.147573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-08</th>\n",
       "      <td>-0.124194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-09</th>\n",
       "      <td>-0.244564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-10</th>\n",
       "      <td>-0.201999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-11</th>\n",
       "      <td>-0.192001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-12</th>\n",
       "      <td>-0.174121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-13</th>\n",
       "      <td>-0.107013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-14</th>\n",
       "      <td>-0.102402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              latest\n",
       "day                 \n",
       "2019-10-05 -0.141922\n",
       "2019-10-06 -0.123334\n",
       "2019-10-07 -0.147573\n",
       "2019-10-08 -0.124194\n",
       "2019-10-09 -0.244564\n",
       "2019-10-10 -0.201999\n",
       "2019-10-11 -0.192001\n",
       "2019-10-12 -0.174121\n",
       "2019-10-13 -0.107013\n",
       "2019-10-14 -0.102402"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = all_day_reward('2019-10-05', '2019-10-14')\n",
    "exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Suggestions On-the-Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_making_single_discount_factor(day_current_str, end_day_str, days_to_trigger, discount = 0):\n",
    "    # day_current_str: YYYY-MM-DD (str) (included)\n",
    "    # end_day_str: YYYY-MM-DD (str) (included)\n",
    "    # days_to_trigger: days to trigger (int)\n",
    "    each_day_reward = all_day_reward(day_current_str, end_day_str)\n",
    "    \n",
    "    # inflate the values on each day\n",
    "    a = np.array([n * ((1 + discount) ** i) for i, n in enumerate(each_day_reward['latest'])])\n",
    "    \n",
    "    # select the 'days_to_trigger' number of days having maximum reward values\n",
    "    selected_days = np.array(each_day_reward.index)[np.argsort(a)[-1:-days_to_trigger-1:-1]]\n",
    "    if day_current_str in selected_days:\n",
    "        print('We suggest triggering on today {}'.format(day_current_str))\n",
    "        output = True\n",
    "    else: \n",
    "        print('We DO NOT suggest triggering on today {}'.format(day_current_str))\n",
    "        output = False\n",
    "    print('And we suggest to trigger by the following sequence: {}'.format(np.array(sorted(selected_days))))\n",
    "    dic = dict(zip(each_day_reward.index, a))\n",
    "    print('The discounted reward values for all the future days are ', dic)\n",
    "    print('Total reward of best path:', sum(np.sort(a)[-5:])) # sum of rewards of selected days\n",
    "    return output\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_making_DP(day_current_str, end_day_str, days_to_trigger, penalty = 0):\n",
    "    # penalty must be positive\n",
    "    \n",
    "    each_day_reward = all_day_reward(day_current_str, end_day_str)\n",
    "    n = len(each_day_reward)\n",
    "    k = days_to_trigger\n",
    "    each_day_penalty = [penalty*i for i in range(n-1,-1,-1)] # define penalty for each day\n",
    "\n",
    "    dp_array = [[0 for j in range(n-k+1)] for i in range(k+1)]\n",
    "    best_path_array = [[[] for j in range(n-k+1)] for i in range(k+1)]\n",
    "\n",
    "    for i in range(k+1): # i = how many days triggered so far\n",
    "        for j in range(n-k+1): # j = how many days skipped so far\n",
    "            if i==0: \n",
    "                trigger = float('-inf')\n",
    "            else:\n",
    "                trigger = dp_array[i-1][j] + each_day_reward.latest.values[i+j-1]\n",
    "            if j==0:\n",
    "                skip = float('-inf')\n",
    "            else:\n",
    "                skip = dp_array[i][j-1] - each_day_penalty[i+j-1]\n",
    "            if i==0 and j==0:\n",
    "                dp_array[i][j] = 0\n",
    "            elif i==k:\n",
    "                dp_array[i][j] = trigger\n",
    "                best_path_array[i][j] = best_path_array[i-1][j] + [i+j-1] # append path\n",
    "            else:\n",
    "                dp_array[i][j] = max(trigger,skip)\n",
    "                if trigger > skip:\n",
    "                    best_path_array[i][j] = best_path_array[i-1][j] + [i+j-1]\n",
    "                else:\n",
    "                    best_path_array[i][j] = best_path_array[i][j-1]\n",
    "            \n",
    "    best_path_reward = np.max(dp_array[-1])\n",
    "    best_path = best_path_array[-1][np.argmax(dp_array[-1])]\n",
    "    best_path = each_day_reward.index[best_path]\n",
    "    return best_path_reward, best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5988641000567898,\n",
       " Index(['2019-10-05', '2019-10-06', '2019-10-08', '2019-10-13', '2019-10-14'], dtype='object', name='day'))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_making_DP('2019-10-05', '2019-10-14', 5, penalty = 0) # critical value 0.006 ~ 0.010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We suggest triggering on today 2019-10-05\n",
      "And we suggest to trigger by the following sequence: ['2019-10-05' '2019-10-06' '2019-10-08' '2019-10-13' '2019-10-14']\n",
      "The discounted reward values for all the future days are  {'2019-10-05': -0.1419219538626451, '2019-10-06': -0.12333368289905193, '2019-10-07': -0.14757341884618774, '2019-10-08': -0.12419393363025463, '2019-10-09': -0.24456410305986243, '2019-10-10': -0.20199926409901492, '2019-10-11': -0.19200071191914517, '2019-10-12': -0.17412137823713936, '2019-10-13': -0.10701275264312339, '2019-10-14': -0.10240177702171466}\n",
      "Total reward of best path: -0.5988641000567897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_making_single_discount_factor('2019-10-05', '2019-10-14',5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_single_discount_factor(days, num_days_trigger, discount):\n",
    "    outputs = []\n",
    "    for curr_day in days:\n",
    "        days_left = int(num_days_trigger - np.sum(outputs))\n",
    "        if days_left == 0:\n",
    "            pass\n",
    "        else:\n",
    "            outputs.append(\\\n",
    "                           decision_making_single_discount_factor\\\n",
    "                           (curr_day, days[-1], days_left, discount))\n",
    "        print(\"\")\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We suggest triggering on today 2019-10-05\n",
      "And we suggest to trigger by the following sequence: ['2019-10-05' '2019-10-06' '2019-10-08' '2019-10-13' '2019-10-14']\n",
      "The discounted reward values for all the future days are  {'2019-10-05': -0.1419219538626451, '2019-10-06': -0.12333368289905193, '2019-10-07': -0.14757341884618774, '2019-10-08': -0.12419393363025463, '2019-10-09': -0.24456410305986243, '2019-10-10': -0.20199926409901492, '2019-10-11': -0.19200071191914517, '2019-10-12': -0.17412137823713936, '2019-10-13': -0.10701275264312339, '2019-10-14': -0.10240177702171466}\n",
      "\n",
      "We DO NOT suggest triggering on today 2019-10-06\n",
      "And we suggest to trigger by the following sequence: ['2019-10-07' '2019-10-08' '2019-10-09' '2019-10-13']\n",
      "The discounted reward values for all the future days are  {'2019-10-06': -0.14313674958912342, '2019-10-07': -0.1303741316447293, '2019-10-08': -0.13293615815997786, '2019-10-09': -0.13367324239719797, '2019-10-10': -0.1839951780364977, '2019-10-11': -0.24301899113097156, '2019-10-12': -0.164977676078602, '2019-10-13': -0.11091696010406843, '2019-10-14': -0.15172601298956567}\n",
      "\n",
      "We suggest triggering on today 2019-10-07\n",
      "And we suggest to trigger by the following sequence: ['2019-10-07' '2019-10-08' '2019-10-09' '2019-10-13']\n",
      "The discounted reward values for all the future days are  {'2019-10-07': -0.1505873959916183, '2019-10-08': -0.12928896059177147, '2019-10-09': -0.13127946894643538, '2019-10-10': -0.19045692585725033, '2019-10-11': -0.1990927717988182, '2019-10-12': -0.18258913904861293, '2019-10-13': -0.14061626414689174, '2019-10-14': -0.18443302800248232}\n",
      "\n",
      "We suggest triggering on today 2019-10-08\n",
      "And we suggest to trigger by the following sequence: ['2019-10-08' '2019-10-09' '2019-10-12']\n",
      "The discounted reward values for all the future days are  {'2019-10-08': -0.14535666168787645, '2019-10-09': -0.12120171043872857, '2019-10-10': -0.25382864620317547, '2019-10-11': -0.1901101910541189, '2019-10-12': -0.14316762030374072, '2019-10-13': -0.16272762257777657, '2019-10-14': -0.1616577499179832}\n",
      "\n",
      "We suggest triggering on today 2019-10-09\n",
      "And we suggest to trigger by the following sequence: ['2019-10-09' '2019-10-13']\n",
      "The discounted reward values for all the future days are  {'2019-10-09': -0.12182330987161279, '2019-10-10': -0.18781168140677235, '2019-10-11': -0.20664171783636787, '2019-10-12': -0.15007186588221325, '2019-10-13': -0.10159081268130803, '2019-10-14': -0.1230554666415768}\n",
      "\n",
      "We DO NOT suggest triggering on today 2019-10-10\n",
      "And we suggest to trigger by the following sequence: ['2019-10-14']\n",
      "The discounted reward values for all the future days are  {'2019-10-10': -0.18256477622331935, '2019-10-11': -0.20770135256874236, '2019-10-12': -0.17128952142466158, '2019-10-13': -0.13407361610222024, '2019-10-14': -0.12757152698151983}\n",
      "\n",
      "We DO NOT suggest triggering on today 2019-10-11\n",
      "And we suggest to trigger by the following sequence: ['2019-10-13']\n",
      "The discounted reward values for all the future days are  {'2019-10-11': -0.239025655731032, '2019-10-12': -0.1612254067296698, '2019-10-13': -0.10631098496109824, '2019-10-14': -0.3761425862587478}\n",
      "\n",
      "We suggest triggering on today 2019-10-12\n",
      "And we suggest to trigger by the following sequence: ['2019-10-12']\n",
      "The discounted reward values for all the future days are  {'2019-10-12': -0.15203692168252048, '2019-10-13': -0.15306740646428987, '2019-10-14': -1.2735659968117825}\n",
      "\n",
      "\n",
      "\n",
      "We suggest triggering on today 2019-10-05\n",
      "And we suggest to trigger by the following sequence: ['2019-10-05' '2019-10-06' '2019-10-07' '2019-10-08' '2019-10-13']\n",
      "The discounted reward values for all the future days are  {'2019-10-05': -0.1419219538626451, '2019-10-06': -0.13566705118895714, '2019-10-07': -0.17856383680388718, '2019-10-08': -0.16530212566186897, '2019-10-09': -0.35806630328994465, '2019-10-10': -0.32532183482410465, '2019-10-11': -0.34014097320819286, '2019-10-12': -0.3393133072462815, '2019-10-13': -0.2293913390930974, '2019-10-14': -0.24145803368264912}\n",
      "\n",
      "We suggest triggering on today 2019-10-06\n",
      "And we suggest to trigger by the following sequence: ['2019-10-06' '2019-10-07' '2019-10-08' '2019-10-09']\n",
      "The discounted reward values for all the future days are  {'2019-10-06': -0.14313674958912342, '2019-10-07': -0.14341154480920223, '2019-10-08': -0.16085275137357324, '2019-10-09': -0.17791908563067055, '2019-10-10': -0.26938734016323634, '2019-10-11': -0.3913845154063411, '2019-10-12': -0.2922680168114844, '2019-10-13': -0.21614577683481606, '2019-10-14': -0.32523818363034784}\n",
      "\n",
      "We suggest triggering on today 2019-10-07\n",
      "And we suggest to trigger by the following sequence: ['2019-10-07' '2019-10-08' '2019-10-09']\n",
      "The discounted reward values for all the future days are  {'2019-10-07': -0.1505873959916183, '2019-10-08': -0.14221785665094863, '2019-10-09': -0.15884815742518685, '2019-10-10': -0.25349816831600025, '2019-10-11': -0.2914917271906498, '2019-10-12': -0.2940616343291817, '2019-10-13': -0.2491102895283318, '2019-10-14': -0.3594077954732164}\n",
      "\n",
      "We suggest triggering on today 2019-10-08\n",
      "And we suggest to trigger by the following sequence: ['2019-10-08' '2019-10-09']\n",
      "The discounted reward values for all the future days are  {'2019-10-08': -0.14535666168787645, '2019-10-09': -0.13332188148260143, '2019-10-10': -0.3071326619058424, '2019-10-11': -0.25303666429303234, '2019-10-12': -0.20961171288670685, '2019-10-13': -0.26207446343773505, '2019-10-14': -0.28638656510245236}\n",
      "\n",
      "We suggest triggering on today 2019-10-09\n",
      "And we suggest to trigger by the following sequence: ['2019-10-09']\n",
      "The discounted reward values for all the future days are  {'2019-10-09': -0.12182330987161279, '2019-10-10': -0.2065928495474496, '2019-10-11': -0.2500364785820052, '2019-10-12': -0.19974565348922588, '2019-10-13': -0.14873910884670313, '2019-10-14': -0.1981820595809259}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "We suggest triggering on today 2019-10-05\n",
      "And we suggest to trigger by the following sequence: ['2019-10-05' '2019-10-06' '2019-10-07' '2019-10-08' '2019-10-09']\n",
      "The discounted reward values for all the future days are  {'2019-10-05': -0.1419219538626451, '2019-10-06': -0.1850005243485779, '2019-10-07': -0.3320401924039224, '2019-10-08': -0.4191545260021094, '2019-10-09': -1.2381057717405535, '2019-10-10': -1.5339319117518946, '2019-10-11': -2.187008109204013, '2019-10-12': -2.9750269859736234, '2019-10-13': -2.742619805045049, '2019-10-14': -3.9366683146843937}\n",
      "\n",
      "We suggest triggering on today 2019-10-06\n",
      "And we suggest to trigger by the following sequence: ['2019-10-06' '2019-10-07' '2019-10-08' '2019-10-09']\n",
      "The discounted reward values for all the future days are  {'2019-10-06': -0.14313674958912342, '2019-10-07': -0.19556119746709394, '2019-10-08': -0.2991063558599502, '2019-10-09': -0.45114719309054313, '2019-10-10': -0.9314755888097697, '2019-10-11': -1.8454254639008152, '2019-10-12': -1.879198841582826, '2019-10-13': -1.8951202480281066, '2019-10-14': -3.888571762595861}\n",
      "\n",
      "We suggest triggering on today 2019-10-07\n",
      "And we suggest to trigger by the following sequence: ['2019-10-07' '2019-10-08' '2019-10-09']\n",
      "The discounted reward values for all the future days are  {'2019-10-07': -0.1505873959916183, '2019-10-08': -0.1939334408876572, '2019-10-09': -0.2953788051294796, '2019-10-10': -0.6427921247682199, '2019-10-11': -1.0079071572315172, '2019-10-12': -1.3865362746504044, '2019-10-13': -1.6017071337981887, '2019-10-14': -3.1512111893861627}\n",
      "\n",
      "We suggest triggering on today 2019-10-08\n",
      "And we suggest to trigger by the following sequence: ['2019-10-08' '2019-10-09']\n",
      "The discounted reward values for all the future days are  {'2019-10-08': -0.14535666168787645, '2019-10-09': -0.18180256565809286, '2019-10-10': -0.5711144539571448, '2019-10-11': -0.6416218948076512, '2019-10-12': -0.7247860777876874, '2019-10-13': -1.2357128839499907, '2019-10-14': -1.8413828076595276}\n",
      "\n",
      "We suggest triggering on today 2019-10-09\n",
      "And we suggest to trigger by the following sequence: ['2019-10-09']\n",
      "The discounted reward values for all the future days are  {'2019-10-09': -0.12182330987161279, '2019-10-10': -0.28171752211015855, '2019-10-11': -0.4649438651318277, '2019-10-12': -0.5064925473524697, '2019-10-13': -0.5143034891991218, '2019-10-14': -0.9344524498094737}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We suggest triggering on today 2019-10-05\n",
      "And we suggest to trigger by the following sequence: ['2019-10-05' '2019-10-06' '2019-10-07' '2019-10-08' '2019-10-09']\n",
      "The discounted reward values for all the future days are  {'2019-10-05': -0.1419219538626451, '2019-10-06': -0.22200062921829347, '2019-10-07': -0.47813787706164834, '2019-10-08': -0.7242990209316451, '2019-10-09': -2.567336128281212, '2019-10-10': -3.8169134546504746, '2019-10-11': -6.530371221953436, '2019-10-12': -10.660059575622558, '2019-10-13': -11.792763152564598, '2019-10-14': -20.312343822449492}\n",
      "\n",
      "We suggest triggering on today 2019-10-06\n",
      "And we suggest to trigger by the following sequence: ['2019-10-06' '2019-10-07' '2019-10-08' '2019-10-09']\n",
      "The discounted reward values for all the future days are  {'2019-10-06': -0.14313674958912342, '2019-10-07': -0.23467343696051274, '2019-10-08': -0.4307131524383283, '2019-10-09': -0.7795823496604587, '2019-10-10': -1.9315077809559382, '2019-10-11': -4.592009090333677, '2019-10-12': -5.611257673784854, '2019-10-13': -6.790558486425551, '2019-10-14': -16.72014681498678}\n",
      "\n",
      "We suggest triggering on today 2019-10-07\n",
      "And we suggest to trigger by the following sequence: ['2019-10-07' '2019-10-08' '2019-10-09']\n",
      "The discounted reward values for all the future days are  {'2019-10-07': -0.1505873959916183, '2019-10-08': -0.23272012906518866, '2019-10-09': -0.4253454793864507, '2019-10-10': -1.1107447915994841, '2019-10-11': -2.089996281235274, '2019-10-12': -3.4501459429380947, '2019-10-13': -4.782671874207251, '2019-10-14': -11.291359430553664}\n",
      "\n",
      "We suggest triggering on today 2019-10-08\n",
      "And we suggest to trigger by the following sequence: ['2019-10-08' '2019-10-09']\n",
      "The discounted reward values for all the future days are  {'2019-10-08': -0.14535666168787645, '2019-10-09': -0.21816307878971145, '2019-10-10': -0.8224048136982886, '2019-10-11': -1.1087226342276215, '2019-10-12': -1.5029164109005486, '2019-10-13': -3.0748490833904416, '2019-10-14': -5.498339601546427}\n",
      "\n",
      "We suggest triggering on today 2019-10-09\n",
      "And we suggest to trigger by the following sequence: ['2019-10-09']\n",
      "The discounted reward values for all the future days are  {'2019-10-09': -0.12182330987161279, '2019-10-10': -0.3380610265321902, '2019-10-11': -0.669519165789832, '2019-10-12': -0.8752191218250678, '2019-10-13': -1.066459715203299, '2019-10-14': -2.32521671990991}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "days = np.array(exp.index)\n",
    "decisions_without_discount = simulate_single_discount_factor(days, 5, 0)\n",
    "decisions_disct_01 = simulate_single_discount_factor(days, 5, 0.1)\n",
    "decisions_disct_05 = simulate_single_discount_factor(days, 5, 0.5)\n",
    "decisions_disct_08 = simulate_single_discount_factor(days, 5, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggested_path_without_discount = days[decisions_without_discount + [False] * (len(days) - len(decisions_without_discount))]\n",
    "suggested_path_disct_01 = days[decisions_disct_01 + [False] * (len(days) - len(decisions_disct_01))]\n",
    "suggested_path_disct_05 = days[decisions_disct_05 + [False] * (len(days) - len(decisions_disct_05))]\n",
    "suggested_path_disct_08 = days[decisions_disct_08 + [False] * (len(days) - len(decisions_disct_08))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_path_afterwards(start_day_str, end_day_str, days_to_trigger, days_have_triggered = None):\n",
    "    # start_day_str: YYYY-MM-DD (str) (included)\n",
    "    # end_day_str: YYYY-MM-DD (str) (included)\n",
    "    # days_to_trigger: days to trigger (int)\n",
    "    # days_have_triggered: days acutally triggered (list of str)\n",
    "    telescopes_day_reward = day_reward(telescopes[0], start_day_str, end_day_str, dict_schedule[telescopes[0]][0], dict_schedule[telescopes[0]][1], use_as_evaluate=True) * dict_weight[telescopes[0]]\n",
    "    for i in telescopes[1:]:\n",
    "        telescopes_day_reward += day_reward(i, start_day_str, end_day_str, dict_schedule[i][0], dict_schedule[i][1], use_as_evaluate=True) * dict_weight[i]\n",
    "    telescopes_day_reward = telescopes_day_reward / sum(weight_telescope)\n",
    "    \n",
    "    all_path = telescopes_day_reward.sort_values(by='latest', ascending = False)\n",
    "    best_path = all_path[:days_to_trigger]\n",
    "    print('The best path to trigger based on ground-truth is {}'\\\n",
    "          .format(np.array(sorted(best_path.index))))\n",
    "    print('The suggested path we predicted on the go is {}'\\\n",
    "         .format(days_have_triggered))\n",
    "    print('The score given to the best path is {}'\\\n",
    "          .format(2 / (1 + np.exp(- best_path['latest'].sum()))))\n",
    "    if days_have_triggered is not None:\n",
    "        print('The score given to the suggested path is {}'\\\n",
    "              .format(2 / (1 + np.exp(- all_path.loc[days_have_triggered]['latest'].sum()))))\n",
    "    return all_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best path to trigger based on ground-truth is ['2019-10-06' '2019-10-07' '2019-10-08' '2019-10-09' '2019-10-12']\n",
      "The suggested path we predicted on the go is ['2019-10-05' '2019-10-07' '2019-10-08' '2019-10-09' '2019-10-12']\n",
      "The score given to the best path is 0.676829584603156\n",
      "The score given to the suggested path is 0.6572095047966228\n",
      "The best path to trigger based on ground-truth is ['2019-10-06' '2019-10-07' '2019-10-08' '2019-10-09' '2019-10-12']\n",
      "The suggested path we predicted on the go is ['2019-10-05' '2019-10-06' '2019-10-07' '2019-10-08' '2019-10-09']\n",
      "The score given to the best path is 0.676829584603156\n",
      "The score given to the suggested path is 0.6659976245053069\n",
      "The best path to trigger based on ground-truth is ['2019-10-06' '2019-10-07' '2019-10-08' '2019-10-09' '2019-10-12']\n",
      "The suggested path we predicted on the go is ['2019-10-05' '2019-10-06' '2019-10-07' '2019-10-08' '2019-10-09']\n",
      "The score given to the best path is 0.676829584603156\n",
      "The score given to the suggested path is 0.6659976245053069\n",
      "The best path to trigger based on ground-truth is ['2019-10-06' '2019-10-07' '2019-10-08' '2019-10-09' '2019-10-12']\n",
      "The suggested path we predicted on the go is ['2019-10-05' '2019-10-06' '2019-10-07' '2019-10-08' '2019-10-09']\n",
      "The score given to the best path is 0.676829584603156\n",
      "The score given to the suggested path is 0.6659976245053069\n"
     ]
    }
   ],
   "source": [
    "all_state = best_path_afterwards('2019-10-05', '2019-10-14', 5, days_have_triggered = suggested_path_without_discount)\n",
    "all_state = best_path_afterwards('2019-10-05', '2019-10-14', 5, days_have_triggered = suggested_path_disct_01)\n",
    "all_state = best_path_afterwards('2019-10-05', '2019-10-14', 5, days_have_triggered = suggested_path_disct_05)\n",
    "all_state = best_path_afterwards('2019-10-05', '2019-10-14', 5, days_have_triggered = suggested_path_disct_08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
