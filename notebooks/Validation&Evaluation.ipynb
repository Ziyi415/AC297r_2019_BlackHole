{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This notebook was developed in src/ folder\n",
    "# # run this if this notebook is in notebooks/ foler\n",
    "# import sys\n",
    "# sys.path.append('../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from model import make_suggestions\n",
    "from model import settings, read_data, processing_data\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one_path(start_date, end_date,databook, std_dict, num_days_left, function, punish_level = 0, distance = True, use_as_evaluate=False):\n",
    "    '''Given a window and forecast data on day 1, return the suggested path. \n",
    "    This is NOT a complete simulation because on the next day, weather forecast get updated and path should be updated.'''\n",
    "    if num_days_left <= 0:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    should_trigger, selected_future_days, confidence_level, each_day_score, _,_= function(start_date, end_date,databook, std_dict, num_days_left, punish_level, distance, use_as_evaluate=use_as_evaluate)\n",
    "\n",
    "    return should_trigger, selected_future_days, confidence_level, each_day_score\n",
    "\n",
    "def simulate(start_date, end_date,databook, std_dict, num_days_left, function, punish_level = 0, distance = True):\n",
    "    '''simulate a complete decision making process in a 10 day window'''\n",
    "    start_dt = datetime.strptime(start_date,\"%Y-%m-%d\")\n",
    "    end_dt = datetime.strptime(end_date,\"%Y-%m-%d\")\n",
    "    date_list = np.arange(start_dt, end_dt+timedelta(days=1),timedelta(days=1)).astype(datetime)\n",
    "    date_list = [t.strftime(\"%Y-%m-%d\") for t in date_list]\n",
    "\n",
    "    path = []\n",
    "    for i,start_date in enumerate(date_list):\n",
    "        should_trigger, _, _, _ = make_one_path(start_date, end_date,databook, std_dict, num_days_left, function, punish_level=punish_level, distance = distance)\n",
    "        if should_trigger:\n",
    "            path.append(start_date)\n",
    "            num_days_left -= 1\n",
    "            \n",
    "    return path\n",
    "\n",
    "def compute_score(start_date, end_date, path, each_day_reward):\n",
    "    '''compute a score given each day reward and path\n",
    "    path: a list of selected dates, e.g. ['2019-11-07', '2019-11-06']\n",
    "    each_day_reward: an array that matchs the length from start_date to end_date\n",
    "    '''\n",
    "    # get consecutive date list whose length = length of each_day_reward\n",
    "    start_date = datetime.strptime(start_date,\"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(end_date,\"%Y-%m-%d\")\n",
    "    date_list = np.arange(start_date, end_date+timedelta(days=1),timedelta(days=1)).astype(datetime)\n",
    "    date_list = [t.strftime(\"%Y-%m-%d\") for t in date_list]\n",
    "    # calculate score for this path\n",
    "    score = 0\n",
    "    for day, reward in zip(date_list,np.array(each_day_reward)):\n",
    "        if day in path:\n",
    "            score += reward\n",
    "    score = score/len(path)\n",
    "    # compare with random path based on predictions if evaluate a future path\n",
    "    _ = np.mean(each_day_reward)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data and ground-truth best path\n",
    "Read in training data and get all consecutive 10-day window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available training data\n",
    "available_data_start = \"2019-10-25\" \n",
    "first_window_start = \"2019-10-26\" # our model requires at least 1 day historical data to compute the variance of weather forecast\n",
    "available_data_end = \"2019-11-30\"\n",
    "\n",
    "# read in data\n",
    "databook, std_dict = read_data.run_read_data(available_data_start, available_data_end)\n",
    "\n",
    "# setting: a 10 choose 5 problem\n",
    "window_length = 10 \n",
    "days_left = 5\n",
    "\n",
    "# make a list of start+end pairs\n",
    "start_end_pair_list = [] \n",
    "start = datetime.strptime(first_window_start,\"%Y-%m-%d\") \n",
    "end = start\n",
    "while end < datetime.strptime(available_data_end,\"%Y-%m-%d\"):\n",
    "    end = start + timedelta(days=window_length-1)\n",
    "    start_end_pair_list.append((start.strftime(\"%Y-%m-%d\"),end.strftime(\"%Y-%m-%d\")))\n",
    "    start = start + timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_end_pair_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get ground-truth best path and best path score in every window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get best path and best path score for each start-end pair\n",
    "path_results = []\n",
    "score_results = []\n",
    "for (start_date, end_date) in start_end_pair_list:\n",
    "\n",
    "    # The best path when we look back, and get true reward at the same time by setting use_as_evaluate=True and default punish level=0\n",
    "    _, best_path, _, each_day_true_reward, _,_ = make_suggestions.decision_making_single_punishment(start_date, end_date,databook, std_dict, days_left, use_as_evaluate=True)\n",
    "\n",
    "    # when look back, scores are all computed from each_day_true_reward which is not discounted\n",
    "    # best path's score when look back\n",
    "    best_path_score = compute_score(start_date, end_date, best_path, each_day_true_reward)\n",
    "\n",
    "    # random path expectation score when look back\n",
    "    random_expect_score = np.mean(each_day_true_reward)\n",
    "    \n",
    "    # record results in the dataframe\n",
    "    path_results.append({'range':(start_date, end_date), 'true_reward':each_day_true_reward,'best_path': best_path})\n",
    "    score_results.append({'range':(start_date, end_date), \\\n",
    "                          'best_score':best_path_score,'random_score':random_expect_score})\n",
    "    \n",
    "path_results = pd.DataFrame.from_dict(path_results, orient='columns')\n",
    "score_results = pd.DataFrame.from_dict(score_results, orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_results.to_csv(\"path_results.csv\")\n",
    "score_results.to_csv(\"score_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: discount factor\n",
    "\n",
    "find best penalty level for method 1: `make_suggestions.decision_making_single_punishment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punish_level_list = [0,0.01, 0.02,0.03,0.04,0.05,0.06,0.08,0.1,0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### get model selected path and score for each start-end pair and different punishment level\n",
    "for pl in  punish_level_list:\n",
    "    path_col = []\n",
    "    score_col = []\n",
    "    for (start_date, end_date) in start_end_pair_list:\n",
    "\n",
    "        # this is the path chosen by our model\n",
    "        # we should update the path every day and get the final path\n",
    "        our_path = simulate(start_date, end_date, databook, std_dict, days_left, \\\n",
    "                make_suggestions.decision_making_single_punishment, pl, settings.baseline_lengths)\n",
    "\n",
    "        # The best path when we look back, and get true reward at the same time by setting use_as_evaluate=True and default punish level=0\n",
    "#         _, best_path, _, each_day_true_reward = make_suggestions.decision_making_single_punishment(start_date, end_date, days_left, use_as_evaluate=True)\n",
    "        each_day_true_reward = path_results['true_reward'][path_results['range']==(start_date, end_date)].values[0]\n",
    "#         # when look back, scores are all computed from each_day_true_reward which is not discounted\n",
    "#         # best path's score when look back\n",
    "#         best_path_score = compute_score(start_date, end_date, best_path, each_day_true_reward)\n",
    "\n",
    "#         # random path expectation score when look back\n",
    "#         random_expect_score = np.mean(each_day_true_reward)\n",
    "        \n",
    "        # our path's score when look back\n",
    "        our_path_score = compute_score(start_date, end_date, our_path, each_day_true_reward)\n",
    "        \n",
    "        print(\"Punish level =\", pl)\n",
    "        print(\"Date range:\", start_date, end_date)\n",
    "        path_col.append(our_path)\n",
    "        score_col.append(our_path_score)\n",
    "    path_results['model1_punish_'+str(pl)] = path_col\n",
    "    score_results['model1_punish_'+str(pl)] = score_col\n",
    "    \n",
    "score_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_results.to_csv(\"path_results.csv\")\n",
    "score_results.to_csv(\"score_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: forecast penalty\n",
    "\n",
    "find best penalty level for method 2: `make_suggestions.decision_making_further_std_punishment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punish_level_list = [0,0.2,0.4,0.6,0.8,1,2,5,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### get model selected path and score for each start-end pair and different punishment level\n",
    "for pl in  punish_level_list:\n",
    "    path_col = []\n",
    "    score_col = []\n",
    "    for (start_date, end_date) in start_end_pair_list:\n",
    "\n",
    "        # this is the path chosen by our model\n",
    "        # we should update the path every day and get the final path\n",
    "        our_path = simulate(start_date, end_date, databook, std_dict, days_left, \\\n",
    "                make_suggestions.decision_making_further_std_punishment, pl, settings.baseline_lengths)\n",
    "\n",
    "        # The best path when we look back, and get true reward at the same time by setting use_as_evaluate=True and default punish level=0\n",
    "#         _, best_path, _, each_day_true_reward = make_suggestions.decision_making_single_punishment(start_date, end_date, days_left, use_as_evaluate=True)\n",
    "        each_day_true_reward = path_results['true_reward'][path_results['range']==(start_date, end_date)].values[0]\n",
    "\n",
    "\n",
    "#         # when look back, scores are all computed from each_day_true_reward which is not discounted\n",
    "#         # best path's score when look back\n",
    "#         best_path_score = compute_score(start_date, end_date, best_path, each_day_true_reward)\n",
    "\n",
    "#         # random path expectation score when look back\n",
    "#         random_expect_score = np.mean(each_day_true_reward)\n",
    "        \n",
    "        # our path's score when look back\n",
    "        our_path_score = compute_score(start_date, end_date, our_path, each_day_true_reward)\n",
    "        \n",
    "        print(\"Punish level =\", pl)\n",
    "        print(\"Date range:\", start_date, end_date)\n",
    "        path_col.append(our_path)\n",
    "        score_col.append(our_path_score)\n",
    "    path_results['model2_punish_'+str(pl)] = path_col\n",
    "    score_results['model2_punish_'+str(pl)] = score_col\n",
    "    \n",
    "score_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_results.to_csv(\"path_results.csv\")\n",
    "score_results.to_csv(\"score_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: prediction difficulty of specific time\n",
    "\n",
    "find best penalty level for method 2: `make_suggestions.decision_making_time_std_punishment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punish_level_list = [0,0.1,0.5,0.6,0.8,1,1.2,3,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get model selected path and score for each start-end pair and different punishment level\n",
    "for pl in  punish_level_list:\n",
    "    path_col = []\n",
    "    score_col = []\n",
    "    for (start_date, end_date) in start_end_pair_list:\n",
    "\n",
    "        # this is the path chosen by our model\n",
    "        # we should update the path every day and get the final path\n",
    "        our_path = simulate(start_date, end_date,databook, std_dict,  days_left, \\\n",
    "                make_suggestions.decision_making_time_std_punishment, pl, settings.baseline_lengths)\n",
    "\n",
    "        # The best path when we look back, and get true reward at the same time by setting use_as_evaluate=True and default punish level=0\n",
    "#         _, best_path, _, each_day_true_reward = make_suggestions.decision_making_single_punishment(start_date, end_date, days_left, use_as_evaluate=True)\n",
    "        each_day_true_reward = path_results['true_reward'][path_results['range']==(start_date, end_date)].values[0]\n",
    "\n",
    "\n",
    "#         # when look back, scores are all computed from each_day_true_reward which is not discounted\n",
    "#         # best path's score when look back\n",
    "#         best_path_score = compute_score(start_date, end_date, best_path, each_day_true_reward)\n",
    "\n",
    "#         # random path expectation score when look back\n",
    "#         random_expect_score = np.mean(each_day_true_reward)\n",
    "        \n",
    "        # our path's score when look back\n",
    "        our_path_score = compute_score(start_date, end_date, our_path, each_day_true_reward)\n",
    "        \n",
    "        print(\"Punish level =\", pl)\n",
    "        print(\"Date range:\", start_date, end_date)\n",
    "        path_col.append(our_path)\n",
    "        score_col.append(our_path_score)\n",
    "    path_results['model3_punish_'+str(pl)] = path_col\n",
    "    score_results['model3_punish_'+str(pl)] = score_col\n",
    "    \n",
    "score_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_results.to_csv(\"path_results.csv\")\n",
    "score_results.to_csv(\"score_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4: sampling from normal\n",
    "\n",
    "no penalty defined for `make_suggestions.decision_making_sampling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "punish_level_list = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punish level = 0\n",
      "Date range: 2019-10-26 2019-11-04\n",
      "Punish level = 0\n",
      "Date range: 2019-10-27 2019-11-05\n",
      "Punish level = 0\n",
      "Date range: 2019-10-28 2019-11-06\n",
      "Punish level = 0\n",
      "Date range: 2019-10-29 2019-11-07\n",
      "Punish level = 0\n",
      "Date range: 2019-10-30 2019-11-08\n",
      "Punish level = 0\n",
      "Date range: 2019-10-31 2019-11-09\n",
      "Punish level = 0\n",
      "Date range: 2019-11-01 2019-11-10\n",
      "Punish level = 0\n",
      "Date range: 2019-11-02 2019-11-11\n",
      "Punish level = 0\n",
      "Date range: 2019-11-03 2019-11-12\n",
      "Punish level = 0\n",
      "Date range: 2019-11-04 2019-11-13\n",
      "Punish level = 0\n",
      "Date range: 2019-11-05 2019-11-14\n",
      "Punish level = 0\n",
      "Date range: 2019-11-06 2019-11-15\n",
      "Punish level = 0\n",
      "Date range: 2019-11-07 2019-11-16\n",
      "Punish level = 0\n",
      "Date range: 2019-11-08 2019-11-17\n",
      "Punish level = 0\n",
      "Date range: 2019-11-09 2019-11-18\n",
      "Punish level = 0\n",
      "Date range: 2019-11-10 2019-11-19\n",
      "Punish level = 0\n",
      "Date range: 2019-11-11 2019-11-20\n",
      "Punish level = 0\n",
      "Date range: 2019-11-12 2019-11-21\n",
      "Punish level = 0\n",
      "Date range: 2019-11-13 2019-11-22\n",
      "Punish level = 0\n",
      "Date range: 2019-11-14 2019-11-23\n",
      "Punish level = 0\n",
      "Date range: 2019-11-15 2019-11-24\n",
      "Punish level = 0\n",
      "Date range: 2019-11-16 2019-11-25\n",
      "Punish level = 0\n",
      "Date range: 2019-11-17 2019-11-26\n",
      "Punish level = 0\n",
      "Date range: 2019-11-18 2019-11-27\n",
      "Punish level = 0\n",
      "Date range: 2019-11-19 2019-11-28\n",
      "Punish level = 0\n",
      "Date range: 2019-11-20 2019-11-29\n",
      "Punish level = 0\n",
      "Date range: 2019-11-21 2019-11-30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>range</th>\n",
       "      <th>best_score</th>\n",
       "      <th>random_score</th>\n",
       "      <th>model1_punish_0</th>\n",
       "      <th>model1_punish_0.04</th>\n",
       "      <th>model1_punish_0.06</th>\n",
       "      <th>model1_punish_0.08</th>\n",
       "      <th>model1_punish_0.1</th>\n",
       "      <th>model1_punish_0.2</th>\n",
       "      <th>model2_punish_0</th>\n",
       "      <th>...</th>\n",
       "      <th>model1_punish_0.02</th>\n",
       "      <th>model1_punish_0.03</th>\n",
       "      <th>model1_punish_0.05</th>\n",
       "      <th>model3_punish_0.8</th>\n",
       "      <th>model3_punish_1.2</th>\n",
       "      <th>model2_punish_0.2</th>\n",
       "      <th>model2_punish_0.4</th>\n",
       "      <th>model2_punish_0.6</th>\n",
       "      <th>model2_punish_0.8</th>\n",
       "      <th>model2_punish_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(2019-10-26, 2019-11-04)</td>\n",
       "      <td>-0.115361</td>\n",
       "      <td>-0.178605</td>\n",
       "      <td>-0.129923</td>\n",
       "      <td>-0.129923</td>\n",
       "      <td>-0.129923</td>\n",
       "      <td>-0.115361</td>\n",
       "      <td>-0.115361</td>\n",
       "      <td>-0.115361</td>\n",
       "      <td>-0.129923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.129923</td>\n",
       "      <td>-0.129923</td>\n",
       "      <td>-0.129923</td>\n",
       "      <td>-0.129923</td>\n",
       "      <td>-0.129923</td>\n",
       "      <td>-0.129923</td>\n",
       "      <td>-0.129923</td>\n",
       "      <td>-0.129923</td>\n",
       "      <td>-0.129923</td>\n",
       "      <td>-0.129923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2019-10-27, 2019-11-05)</td>\n",
       "      <td>-0.112848</td>\n",
       "      <td>-0.177348</td>\n",
       "      <td>-0.121363</td>\n",
       "      <td>-0.112848</td>\n",
       "      <td>-0.112848</td>\n",
       "      <td>-0.112848</td>\n",
       "      <td>-0.112848</td>\n",
       "      <td>-0.138066</td>\n",
       "      <td>-0.121363</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121363</td>\n",
       "      <td>-0.112848</td>\n",
       "      <td>-0.112848</td>\n",
       "      <td>-0.112848</td>\n",
       "      <td>-0.112848</td>\n",
       "      <td>-0.121363</td>\n",
       "      <td>-0.121363</td>\n",
       "      <td>-0.112848</td>\n",
       "      <td>-0.112848</td>\n",
       "      <td>-0.112848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2019-10-28, 2019-11-06)</td>\n",
       "      <td>-0.110988</td>\n",
       "      <td>-0.176418</td>\n",
       "      <td>-0.110988</td>\n",
       "      <td>-0.110988</td>\n",
       "      <td>-0.110988</td>\n",
       "      <td>-0.110988</td>\n",
       "      <td>-0.110988</td>\n",
       "      <td>-0.134516</td>\n",
       "      <td>-0.110988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110988</td>\n",
       "      <td>-0.110988</td>\n",
       "      <td>-0.110988</td>\n",
       "      <td>-0.110988</td>\n",
       "      <td>-0.110988</td>\n",
       "      <td>-0.110988</td>\n",
       "      <td>-0.110988</td>\n",
       "      <td>-0.110988</td>\n",
       "      <td>-0.110988</td>\n",
       "      <td>-0.110988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(2019-10-29, 2019-11-07)</td>\n",
       "      <td>-0.109763</td>\n",
       "      <td>-0.175806</td>\n",
       "      <td>-0.109763</td>\n",
       "      <td>-0.109763</td>\n",
       "      <td>-0.109763</td>\n",
       "      <td>-0.109763</td>\n",
       "      <td>-0.109763</td>\n",
       "      <td>-0.133291</td>\n",
       "      <td>-0.109763</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109763</td>\n",
       "      <td>-0.109763</td>\n",
       "      <td>-0.109763</td>\n",
       "      <td>-0.109763</td>\n",
       "      <td>-0.109763</td>\n",
       "      <td>-0.109763</td>\n",
       "      <td>-0.109763</td>\n",
       "      <td>-0.109763</td>\n",
       "      <td>-0.109763</td>\n",
       "      <td>-0.109763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(2019-10-30, 2019-11-08)</td>\n",
       "      <td>-0.106439</td>\n",
       "      <td>-0.174144</td>\n",
       "      <td>-0.106439</td>\n",
       "      <td>-0.106439</td>\n",
       "      <td>-0.106439</td>\n",
       "      <td>-0.106439</td>\n",
       "      <td>-0.106439</td>\n",
       "      <td>-0.158580</td>\n",
       "      <td>-0.106439</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106439</td>\n",
       "      <td>-0.106439</td>\n",
       "      <td>-0.106439</td>\n",
       "      <td>-0.106439</td>\n",
       "      <td>-0.106439</td>\n",
       "      <td>-0.106439</td>\n",
       "      <td>-0.106439</td>\n",
       "      <td>-0.106439</td>\n",
       "      <td>-0.106439</td>\n",
       "      <td>-0.106439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(2019-10-31, 2019-11-09)</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.170800</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.114955</td>\n",
       "      <td>-0.114955</td>\n",
       "      <td>-0.114955</td>\n",
       "      <td>-0.151031</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(2019-11-01, 2019-11-10)</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.162239</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.114955</td>\n",
       "      <td>-0.114955</td>\n",
       "      <td>-0.114955</td>\n",
       "      <td>-0.153419</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(2019-11-02, 2019-11-11)</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.157961</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.114955</td>\n",
       "      <td>-0.114955</td>\n",
       "      <td>-0.114955</td>\n",
       "      <td>-0.140871</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(2019-11-03, 2019-11-12)</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.156580</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.114955</td>\n",
       "      <td>-0.114955</td>\n",
       "      <td>-0.114955</td>\n",
       "      <td>-0.114955</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2019-11-04, 2019-11-13)</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.138074</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.114955</td>\n",
       "      <td>-0.114955</td>\n",
       "      <td>-0.114955</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(2019-11-05, 2019-11-14)</td>\n",
       "      <td>-0.097748</td>\n",
       "      <td>-0.129471</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "      <td>-0.099752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(2019-11-06, 2019-11-15)</td>\n",
       "      <td>-0.099621</td>\n",
       "      <td>-0.133849</td>\n",
       "      <td>-0.099621</td>\n",
       "      <td>-0.099621</td>\n",
       "      <td>-0.107849</td>\n",
       "      <td>-0.107849</td>\n",
       "      <td>-0.107849</td>\n",
       "      <td>-0.107849</td>\n",
       "      <td>-0.099621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099621</td>\n",
       "      <td>-0.099621</td>\n",
       "      <td>-0.107849</td>\n",
       "      <td>-0.099621</td>\n",
       "      <td>-0.099621</td>\n",
       "      <td>-0.099621</td>\n",
       "      <td>-0.099621</td>\n",
       "      <td>-0.099621</td>\n",
       "      <td>-0.099621</td>\n",
       "      <td>-0.107849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(2019-11-07, 2019-11-16)</td>\n",
       "      <td>-0.101499</td>\n",
       "      <td>-0.144381</td>\n",
       "      <td>-0.106687</td>\n",
       "      <td>-0.106027</td>\n",
       "      <td>-0.106027</td>\n",
       "      <td>-0.106027</td>\n",
       "      <td>-0.106027</td>\n",
       "      <td>-0.109726</td>\n",
       "      <td>-0.106687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106687</td>\n",
       "      <td>-0.106027</td>\n",
       "      <td>-0.106027</td>\n",
       "      <td>-0.106687</td>\n",
       "      <td>-0.106687</td>\n",
       "      <td>-0.106687</td>\n",
       "      <td>-0.106687</td>\n",
       "      <td>-0.106687</td>\n",
       "      <td>-0.106687</td>\n",
       "      <td>-0.106027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(2019-11-08, 2019-11-17)</td>\n",
       "      <td>-0.108584</td>\n",
       "      <td>-0.160169</td>\n",
       "      <td>-0.109244</td>\n",
       "      <td>-0.113772</td>\n",
       "      <td>-0.108584</td>\n",
       "      <td>-0.108584</td>\n",
       "      <td>-0.108584</td>\n",
       "      <td>-0.108584</td>\n",
       "      <td>-0.109244</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113772</td>\n",
       "      <td>-0.113772</td>\n",
       "      <td>-0.113772</td>\n",
       "      <td>-0.109244</td>\n",
       "      <td>-0.113772</td>\n",
       "      <td>-0.109244</td>\n",
       "      <td>-0.113772</td>\n",
       "      <td>-0.113772</td>\n",
       "      <td>-0.113772</td>\n",
       "      <td>-0.113772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(2019-11-09, 2019-11-18)</td>\n",
       "      <td>-0.123905</td>\n",
       "      <td>-0.176276</td>\n",
       "      <td>-0.136875</td>\n",
       "      <td>-0.123905</td>\n",
       "      <td>-0.123905</td>\n",
       "      <td>-0.136215</td>\n",
       "      <td>-0.136215</td>\n",
       "      <td>-0.136215</td>\n",
       "      <td>-0.136875</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123905</td>\n",
       "      <td>-0.123905</td>\n",
       "      <td>-0.123905</td>\n",
       "      <td>-0.136875</td>\n",
       "      <td>-0.123905</td>\n",
       "      <td>-0.136875</td>\n",
       "      <td>-0.123905</td>\n",
       "      <td>-0.123905</td>\n",
       "      <td>-0.123905</td>\n",
       "      <td>-0.123905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(2019-11-10, 2019-11-19)</td>\n",
       "      <td>-0.143099</td>\n",
       "      <td>-0.193628</td>\n",
       "      <td>-0.157757</td>\n",
       "      <td>-0.143099</td>\n",
       "      <td>-0.143099</td>\n",
       "      <td>-0.143099</td>\n",
       "      <td>-0.143099</td>\n",
       "      <td>-0.159189</td>\n",
       "      <td>-0.157757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143099</td>\n",
       "      <td>-0.143099</td>\n",
       "      <td>-0.143099</td>\n",
       "      <td>-0.144787</td>\n",
       "      <td>-0.144787</td>\n",
       "      <td>-0.157757</td>\n",
       "      <td>-0.143099</td>\n",
       "      <td>-0.143099</td>\n",
       "      <td>-0.143099</td>\n",
       "      <td>-0.143099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(2019-11-11, 2019-11-20)</td>\n",
       "      <td>-0.152640</td>\n",
       "      <td>-0.198398</td>\n",
       "      <td>-0.154329</td>\n",
       "      <td>-0.157757</td>\n",
       "      <td>-0.157757</td>\n",
       "      <td>-0.159849</td>\n",
       "      <td>-0.159849</td>\n",
       "      <td>-0.159849</td>\n",
       "      <td>-0.154329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157757</td>\n",
       "      <td>-0.157757</td>\n",
       "      <td>-0.157757</td>\n",
       "      <td>-0.154329</td>\n",
       "      <td>-0.154329</td>\n",
       "      <td>-0.157757</td>\n",
       "      <td>-0.157757</td>\n",
       "      <td>-0.157757</td>\n",
       "      <td>-0.157757</td>\n",
       "      <td>-0.157757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(2019-11-12, 2019-11-21)</td>\n",
       "      <td>-0.150153</td>\n",
       "      <td>-0.197155</td>\n",
       "      <td>-0.155269</td>\n",
       "      <td>-0.155269</td>\n",
       "      <td>-0.155269</td>\n",
       "      <td>-0.161537</td>\n",
       "      <td>-0.161537</td>\n",
       "      <td>-0.161537</td>\n",
       "      <td>-0.155269</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155269</td>\n",
       "      <td>-0.155269</td>\n",
       "      <td>-0.155269</td>\n",
       "      <td>-0.154329</td>\n",
       "      <td>-0.154329</td>\n",
       "      <td>-0.155269</td>\n",
       "      <td>-0.155269</td>\n",
       "      <td>-0.155269</td>\n",
       "      <td>-0.155269</td>\n",
       "      <td>-0.154329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(2019-11-13, 2019-11-22)</td>\n",
       "      <td>-0.150153</td>\n",
       "      <td>-0.207514</td>\n",
       "      <td>-0.150153</td>\n",
       "      <td>-0.155269</td>\n",
       "      <td>-0.155269</td>\n",
       "      <td>-0.154329</td>\n",
       "      <td>-0.154329</td>\n",
       "      <td>-0.162340</td>\n",
       "      <td>-0.150153</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155269</td>\n",
       "      <td>-0.155269</td>\n",
       "      <td>-0.155269</td>\n",
       "      <td>-0.154329</td>\n",
       "      <td>-0.154329</td>\n",
       "      <td>-0.155269</td>\n",
       "      <td>-0.155269</td>\n",
       "      <td>-0.155269</td>\n",
       "      <td>-0.155269</td>\n",
       "      <td>-0.154329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(2019-11-14, 2019-11-23)</td>\n",
       "      <td>-0.159568</td>\n",
       "      <td>-0.212221</td>\n",
       "      <td>-0.159568</td>\n",
       "      <td>-0.163743</td>\n",
       "      <td>-0.169340</td>\n",
       "      <td>-0.169340</td>\n",
       "      <td>-0.176410</td>\n",
       "      <td>-0.191359</td>\n",
       "      <td>-0.159568</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164684</td>\n",
       "      <td>-0.164684</td>\n",
       "      <td>-0.169340</td>\n",
       "      <td>-0.163743</td>\n",
       "      <td>-0.163743</td>\n",
       "      <td>-0.164684</td>\n",
       "      <td>-0.164684</td>\n",
       "      <td>-0.164684</td>\n",
       "      <td>-0.164684</td>\n",
       "      <td>-0.163743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(2019-11-15, 2019-11-24)</td>\n",
       "      <td>-0.166247</td>\n",
       "      <td>-0.215561</td>\n",
       "      <td>-0.166247</td>\n",
       "      <td>-0.170423</td>\n",
       "      <td>-0.176020</td>\n",
       "      <td>-0.176020</td>\n",
       "      <td>-0.183090</td>\n",
       "      <td>-0.228066</td>\n",
       "      <td>-0.166247</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171364</td>\n",
       "      <td>-0.171364</td>\n",
       "      <td>-0.176020</td>\n",
       "      <td>-0.170423</td>\n",
       "      <td>-0.170423</td>\n",
       "      <td>-0.171364</td>\n",
       "      <td>-0.171364</td>\n",
       "      <td>-0.171364</td>\n",
       "      <td>-0.171364</td>\n",
       "      <td>-0.170423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(2019-11-16, 2019-11-25)</td>\n",
       "      <td>-0.162702</td>\n",
       "      <td>-0.213789</td>\n",
       "      <td>-0.162702</td>\n",
       "      <td>-0.172474</td>\n",
       "      <td>-0.172474</td>\n",
       "      <td>-0.172474</td>\n",
       "      <td>-0.191575</td>\n",
       "      <td>-0.236948</td>\n",
       "      <td>-0.162702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167819</td>\n",
       "      <td>-0.167819</td>\n",
       "      <td>-0.172474</td>\n",
       "      <td>-0.166878</td>\n",
       "      <td>-0.185817</td>\n",
       "      <td>-0.167819</td>\n",
       "      <td>-0.167819</td>\n",
       "      <td>-0.167819</td>\n",
       "      <td>-0.167819</td>\n",
       "      <td>-0.190472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(2019-11-17, 2019-11-26)</td>\n",
       "      <td>-0.140773</td>\n",
       "      <td>-0.200736</td>\n",
       "      <td>-0.141714</td>\n",
       "      <td>-0.146369</td>\n",
       "      <td>-0.146369</td>\n",
       "      <td>-0.146369</td>\n",
       "      <td>-0.165470</td>\n",
       "      <td>-0.232772</td>\n",
       "      <td>-0.141714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141714</td>\n",
       "      <td>-0.141714</td>\n",
       "      <td>-0.146369</td>\n",
       "      <td>-0.140773</td>\n",
       "      <td>-0.159711</td>\n",
       "      <td>-0.141714</td>\n",
       "      <td>-0.141714</td>\n",
       "      <td>-0.141714</td>\n",
       "      <td>-0.141714</td>\n",
       "      <td>-0.164367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(2019-11-18, 2019-11-27)</td>\n",
       "      <td>-0.117579</td>\n",
       "      <td>-0.181665</td>\n",
       "      <td>-0.117579</td>\n",
       "      <td>-0.123175</td>\n",
       "      <td>-0.123175</td>\n",
       "      <td>-0.134264</td>\n",
       "      <td>-0.141335</td>\n",
       "      <td>-0.196835</td>\n",
       "      <td>-0.117579</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117579</td>\n",
       "      <td>-0.123175</td>\n",
       "      <td>-0.123175</td>\n",
       "      <td>-0.117579</td>\n",
       "      <td>-0.117579</td>\n",
       "      <td>-0.117579</td>\n",
       "      <td>-0.117579</td>\n",
       "      <td>-0.117579</td>\n",
       "      <td>-0.117579</td>\n",
       "      <td>-0.122234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(2019-11-19, 2019-11-28)</td>\n",
       "      <td>-0.098522</td>\n",
       "      <td>-0.165803</td>\n",
       "      <td>-0.098522</td>\n",
       "      <td>-0.098522</td>\n",
       "      <td>-0.110552</td>\n",
       "      <td>-0.109611</td>\n",
       "      <td>-0.109611</td>\n",
       "      <td>-0.165630</td>\n",
       "      <td>-0.098522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098522</td>\n",
       "      <td>-0.098522</td>\n",
       "      <td>-0.110552</td>\n",
       "      <td>-0.098522</td>\n",
       "      <td>-0.098522</td>\n",
       "      <td>-0.098522</td>\n",
       "      <td>-0.098522</td>\n",
       "      <td>-0.098522</td>\n",
       "      <td>-0.098522</td>\n",
       "      <td>-0.098522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(2019-11-20, 2019-11-29)</td>\n",
       "      <td>-0.093469</td>\n",
       "      <td>-0.148263</td>\n",
       "      <td>-0.093469</td>\n",
       "      <td>-0.098522</td>\n",
       "      <td>-0.110552</td>\n",
       "      <td>-0.110552</td>\n",
       "      <td>-0.109611</td>\n",
       "      <td>-0.134264</td>\n",
       "      <td>-0.093469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093469</td>\n",
       "      <td>-0.093469</td>\n",
       "      <td>-0.098522</td>\n",
       "      <td>-0.098522</td>\n",
       "      <td>-0.098522</td>\n",
       "      <td>-0.093469</td>\n",
       "      <td>-0.093469</td>\n",
       "      <td>-0.093469</td>\n",
       "      <td>-0.098522</td>\n",
       "      <td>-0.098522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(2019-11-21, 2019-11-30)</td>\n",
       "      <td>-0.083840</td>\n",
       "      <td>-0.137235</td>\n",
       "      <td>-0.087555</td>\n",
       "      <td>-0.087555</td>\n",
       "      <td>-0.098522</td>\n",
       "      <td>-0.110552</td>\n",
       "      <td>-0.110552</td>\n",
       "      <td>-0.129609</td>\n",
       "      <td>-0.087555</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087555</td>\n",
       "      <td>-0.087555</td>\n",
       "      <td>-0.098522</td>\n",
       "      <td>-0.087555</td>\n",
       "      <td>-0.087555</td>\n",
       "      <td>-0.087555</td>\n",
       "      <td>-0.087555</td>\n",
       "      <td>-0.087555</td>\n",
       "      <td>-0.087555</td>\n",
       "      <td>-0.098522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       range  best_score  random_score  model1_punish_0  \\\n",
       "0   (2019-10-26, 2019-11-04)   -0.115361     -0.178605        -0.129923   \n",
       "1   (2019-10-27, 2019-11-05)   -0.112848     -0.177348        -0.121363   \n",
       "2   (2019-10-28, 2019-11-06)   -0.110988     -0.176418        -0.110988   \n",
       "3   (2019-10-29, 2019-11-07)   -0.109763     -0.175806        -0.109763   \n",
       "4   (2019-10-30, 2019-11-08)   -0.106439     -0.174144        -0.106439   \n",
       "5   (2019-10-31, 2019-11-09)   -0.099752     -0.170800        -0.099752   \n",
       "6   (2019-11-01, 2019-11-10)   -0.099752     -0.162239        -0.099752   \n",
       "7   (2019-11-02, 2019-11-11)   -0.099752     -0.157961        -0.099752   \n",
       "8   (2019-11-03, 2019-11-12)   -0.099752     -0.156580        -0.099752   \n",
       "9   (2019-11-04, 2019-11-13)   -0.099752     -0.138074        -0.099752   \n",
       "10  (2019-11-05, 2019-11-14)   -0.097748     -0.129471        -0.099752   \n",
       "11  (2019-11-06, 2019-11-15)   -0.099621     -0.133849        -0.099621   \n",
       "12  (2019-11-07, 2019-11-16)   -0.101499     -0.144381        -0.106687   \n",
       "13  (2019-11-08, 2019-11-17)   -0.108584     -0.160169        -0.109244   \n",
       "14  (2019-11-09, 2019-11-18)   -0.123905     -0.176276        -0.136875   \n",
       "15  (2019-11-10, 2019-11-19)   -0.143099     -0.193628        -0.157757   \n",
       "16  (2019-11-11, 2019-11-20)   -0.152640     -0.198398        -0.154329   \n",
       "17  (2019-11-12, 2019-11-21)   -0.150153     -0.197155        -0.155269   \n",
       "18  (2019-11-13, 2019-11-22)   -0.150153     -0.207514        -0.150153   \n",
       "19  (2019-11-14, 2019-11-23)   -0.159568     -0.212221        -0.159568   \n",
       "20  (2019-11-15, 2019-11-24)   -0.166247     -0.215561        -0.166247   \n",
       "21  (2019-11-16, 2019-11-25)   -0.162702     -0.213789        -0.162702   \n",
       "22  (2019-11-17, 2019-11-26)   -0.140773     -0.200736        -0.141714   \n",
       "23  (2019-11-18, 2019-11-27)   -0.117579     -0.181665        -0.117579   \n",
       "24  (2019-11-19, 2019-11-28)   -0.098522     -0.165803        -0.098522   \n",
       "25  (2019-11-20, 2019-11-29)   -0.093469     -0.148263        -0.093469   \n",
       "26  (2019-11-21, 2019-11-30)   -0.083840     -0.137235        -0.087555   \n",
       "\n",
       "    model1_punish_0.04  model1_punish_0.06  model1_punish_0.08  \\\n",
       "0            -0.129923           -0.129923           -0.115361   \n",
       "1            -0.112848           -0.112848           -0.112848   \n",
       "2            -0.110988           -0.110988           -0.110988   \n",
       "3            -0.109763           -0.109763           -0.109763   \n",
       "4            -0.106439           -0.106439           -0.106439   \n",
       "5            -0.099752           -0.114955           -0.114955   \n",
       "6            -0.099752           -0.114955           -0.114955   \n",
       "7            -0.099752           -0.114955           -0.114955   \n",
       "8            -0.099752           -0.114955           -0.114955   \n",
       "9            -0.099752           -0.099752           -0.114955   \n",
       "10           -0.099752           -0.099752           -0.099752   \n",
       "11           -0.099621           -0.107849           -0.107849   \n",
       "12           -0.106027           -0.106027           -0.106027   \n",
       "13           -0.113772           -0.108584           -0.108584   \n",
       "14           -0.123905           -0.123905           -0.136215   \n",
       "15           -0.143099           -0.143099           -0.143099   \n",
       "16           -0.157757           -0.157757           -0.159849   \n",
       "17           -0.155269           -0.155269           -0.161537   \n",
       "18           -0.155269           -0.155269           -0.154329   \n",
       "19           -0.163743           -0.169340           -0.169340   \n",
       "20           -0.170423           -0.176020           -0.176020   \n",
       "21           -0.172474           -0.172474           -0.172474   \n",
       "22           -0.146369           -0.146369           -0.146369   \n",
       "23           -0.123175           -0.123175           -0.134264   \n",
       "24           -0.098522           -0.110552           -0.109611   \n",
       "25           -0.098522           -0.110552           -0.110552   \n",
       "26           -0.087555           -0.098522           -0.110552   \n",
       "\n",
       "    model1_punish_0.1  model1_punish_0.2  model2_punish_0  ...  \\\n",
       "0           -0.115361          -0.115361        -0.129923  ...   \n",
       "1           -0.112848          -0.138066        -0.121363  ...   \n",
       "2           -0.110988          -0.134516        -0.110988  ...   \n",
       "3           -0.109763          -0.133291        -0.109763  ...   \n",
       "4           -0.106439          -0.158580        -0.106439  ...   \n",
       "5           -0.114955          -0.151031        -0.099752  ...   \n",
       "6           -0.114955          -0.153419        -0.099752  ...   \n",
       "7           -0.114955          -0.140871        -0.099752  ...   \n",
       "8           -0.114955          -0.114955        -0.099752  ...   \n",
       "9           -0.114955          -0.114955        -0.099752  ...   \n",
       "10          -0.099752          -0.099752        -0.099752  ...   \n",
       "11          -0.107849          -0.107849        -0.099621  ...   \n",
       "12          -0.106027          -0.109726        -0.106687  ...   \n",
       "13          -0.108584          -0.108584        -0.109244  ...   \n",
       "14          -0.136215          -0.136215        -0.136875  ...   \n",
       "15          -0.143099          -0.159189        -0.157757  ...   \n",
       "16          -0.159849          -0.159849        -0.154329  ...   \n",
       "17          -0.161537          -0.161537        -0.155269  ...   \n",
       "18          -0.154329          -0.162340        -0.150153  ...   \n",
       "19          -0.176410          -0.191359        -0.159568  ...   \n",
       "20          -0.183090          -0.228066        -0.166247  ...   \n",
       "21          -0.191575          -0.236948        -0.162702  ...   \n",
       "22          -0.165470          -0.232772        -0.141714  ...   \n",
       "23          -0.141335          -0.196835        -0.117579  ...   \n",
       "24          -0.109611          -0.165630        -0.098522  ...   \n",
       "25          -0.109611          -0.134264        -0.093469  ...   \n",
       "26          -0.110552          -0.129609        -0.087555  ...   \n",
       "\n",
       "    model1_punish_0.02  model1_punish_0.03  model1_punish_0.05  \\\n",
       "0            -0.129923           -0.129923           -0.129923   \n",
       "1            -0.121363           -0.112848           -0.112848   \n",
       "2            -0.110988           -0.110988           -0.110988   \n",
       "3            -0.109763           -0.109763           -0.109763   \n",
       "4            -0.106439           -0.106439           -0.106439   \n",
       "5            -0.099752           -0.099752           -0.099752   \n",
       "6            -0.099752           -0.099752           -0.099752   \n",
       "7            -0.099752           -0.099752           -0.099752   \n",
       "8            -0.099752           -0.099752           -0.099752   \n",
       "9            -0.099752           -0.099752           -0.099752   \n",
       "10           -0.099752           -0.099752           -0.099752   \n",
       "11           -0.099621           -0.099621           -0.107849   \n",
       "12           -0.106687           -0.106027           -0.106027   \n",
       "13           -0.113772           -0.113772           -0.113772   \n",
       "14           -0.123905           -0.123905           -0.123905   \n",
       "15           -0.143099           -0.143099           -0.143099   \n",
       "16           -0.157757           -0.157757           -0.157757   \n",
       "17           -0.155269           -0.155269           -0.155269   \n",
       "18           -0.155269           -0.155269           -0.155269   \n",
       "19           -0.164684           -0.164684           -0.169340   \n",
       "20           -0.171364           -0.171364           -0.176020   \n",
       "21           -0.167819           -0.167819           -0.172474   \n",
       "22           -0.141714           -0.141714           -0.146369   \n",
       "23           -0.117579           -0.123175           -0.123175   \n",
       "24           -0.098522           -0.098522           -0.110552   \n",
       "25           -0.093469           -0.093469           -0.098522   \n",
       "26           -0.087555           -0.087555           -0.098522   \n",
       "\n",
       "    model3_punish_0.8  model3_punish_1.2  model2_punish_0.2  \\\n",
       "0           -0.129923          -0.129923          -0.129923   \n",
       "1           -0.112848          -0.112848          -0.121363   \n",
       "2           -0.110988          -0.110988          -0.110988   \n",
       "3           -0.109763          -0.109763          -0.109763   \n",
       "4           -0.106439          -0.106439          -0.106439   \n",
       "5           -0.099752          -0.099752          -0.099752   \n",
       "6           -0.099752          -0.099752          -0.099752   \n",
       "7           -0.099752          -0.099752          -0.099752   \n",
       "8           -0.099752          -0.099752          -0.099752   \n",
       "9           -0.099752          -0.099752          -0.099752   \n",
       "10          -0.099752          -0.099752          -0.099752   \n",
       "11          -0.099621          -0.099621          -0.099621   \n",
       "12          -0.106687          -0.106687          -0.106687   \n",
       "13          -0.109244          -0.113772          -0.109244   \n",
       "14          -0.136875          -0.123905          -0.136875   \n",
       "15          -0.144787          -0.144787          -0.157757   \n",
       "16          -0.154329          -0.154329          -0.157757   \n",
       "17          -0.154329          -0.154329          -0.155269   \n",
       "18          -0.154329          -0.154329          -0.155269   \n",
       "19          -0.163743          -0.163743          -0.164684   \n",
       "20          -0.170423          -0.170423          -0.171364   \n",
       "21          -0.166878          -0.185817          -0.167819   \n",
       "22          -0.140773          -0.159711          -0.141714   \n",
       "23          -0.117579          -0.117579          -0.117579   \n",
       "24          -0.098522          -0.098522          -0.098522   \n",
       "25          -0.098522          -0.098522          -0.093469   \n",
       "26          -0.087555          -0.087555          -0.087555   \n",
       "\n",
       "    model2_punish_0.4  model2_punish_0.6  model2_punish_0.8  model2_punish_2  \n",
       "0           -0.129923          -0.129923          -0.129923        -0.129923  \n",
       "1           -0.121363          -0.112848          -0.112848        -0.112848  \n",
       "2           -0.110988          -0.110988          -0.110988        -0.110988  \n",
       "3           -0.109763          -0.109763          -0.109763        -0.109763  \n",
       "4           -0.106439          -0.106439          -0.106439        -0.106439  \n",
       "5           -0.099752          -0.099752          -0.099752        -0.099752  \n",
       "6           -0.099752          -0.099752          -0.099752        -0.099752  \n",
       "7           -0.099752          -0.099752          -0.099752        -0.099752  \n",
       "8           -0.099752          -0.099752          -0.099752        -0.099752  \n",
       "9           -0.099752          -0.099752          -0.099752        -0.099752  \n",
       "10          -0.099752          -0.099752          -0.099752        -0.099752  \n",
       "11          -0.099621          -0.099621          -0.099621        -0.107849  \n",
       "12          -0.106687          -0.106687          -0.106687        -0.106027  \n",
       "13          -0.113772          -0.113772          -0.113772        -0.113772  \n",
       "14          -0.123905          -0.123905          -0.123905        -0.123905  \n",
       "15          -0.143099          -0.143099          -0.143099        -0.143099  \n",
       "16          -0.157757          -0.157757          -0.157757        -0.157757  \n",
       "17          -0.155269          -0.155269          -0.155269        -0.154329  \n",
       "18          -0.155269          -0.155269          -0.155269        -0.154329  \n",
       "19          -0.164684          -0.164684          -0.164684        -0.163743  \n",
       "20          -0.171364          -0.171364          -0.171364        -0.170423  \n",
       "21          -0.167819          -0.167819          -0.167819        -0.190472  \n",
       "22          -0.141714          -0.141714          -0.141714        -0.164367  \n",
       "23          -0.117579          -0.117579          -0.117579        -0.122234  \n",
       "24          -0.098522          -0.098522          -0.098522        -0.098522  \n",
       "25          -0.093469          -0.093469          -0.098522        -0.098522  \n",
       "26          -0.087555          -0.087555          -0.087555        -0.098522  \n",
       "\n",
       "[27 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### get model selected path and score for each start-end pair and different punishment level\n",
    "for pl in  punish_level_list:\n",
    "    path_col = []\n",
    "    score_col = []\n",
    "    for (start_date, end_date) in start_end_pair_list:\n",
    "\n",
    "        # this is the path chosen by our model\n",
    "        # we should update the path every day and get the final path\n",
    "        our_path = simulate(start_date, end_date, databook, std_dict, days_left, \\\n",
    "                make_suggestions.decision_making_sampling, pl, settings.baseline_lengths)\n",
    "\n",
    "        # The best path when we look back, and get true reward at the same time by setting use_as_evaluate=True and default punish level=0\n",
    "#         _, best_path, _, each_day_true_reward = make_suggestions.decision_making_single_punishment(start_date, end_date, days_left, use_as_evaluate=True)\n",
    "        each_day_true_reward = path_results['true_reward'][path_results['range']==(start_date, end_date)].values[0]\n",
    "\n",
    "\n",
    "#         # when look back, scores are all computed from each_day_true_reward which is not discounted\n",
    "#         # best path's score when look back\n",
    "#         best_path_score = compute_score(start_date, end_date, best_path, each_day_true_reward)\n",
    "\n",
    "#         # random path expectation score when look back\n",
    "#         random_expect_score = np.mean(each_day_true_reward)\n",
    "        \n",
    "        # our path's score when look back\n",
    "        our_path_score = compute_score(start_date, end_date, our_path, each_day_true_reward)\n",
    "        \n",
    "        print(\"Punish level =\", pl)\n",
    "        print(\"Date range:\", start_date, end_date)\n",
    "        path_col.append(our_path)\n",
    "        score_col.append(our_path_score)\n",
    "    path_results['model4_punish_'+str(pl)] = path_col\n",
    "    score_results['model4_punish_'+str(pl)] = score_col\n",
    "    \n",
    "score_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_results.to_csv(\"path_results.csv\")\n",
    "score_results.to_csv(\"score_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload result dataset\n",
    "path_results = pd.read_csv(\"evaluation_results/path_results.csv\", index_col = 0)\n",
    "score_results = pd.read_csv(\"evaluation_results/score_results.csv\", index_col = 0)\n",
    "\n",
    "# some data formatting was changed when we save csv, so we change it back\n",
    "convert_reward = lambda x: [float(a.strip(\",\\n\")) for a in x.strip(\"[] \").split(\" \") if a != \"\"]\n",
    "path_results['true_reward'] = path_results['true_reward'].apply(convert_reward)\n",
    "path_results['range'] = path_results['range'].apply(lambda x: eval(x))\n",
    "path_results['best_path'] = path_results['best_path'].apply(lambda x: [d.strip(\"''\") for d in x.strip(\"[]\").split(\" \")])\n",
    "score_results['range'] = score_results['range'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See result for one window: (11/09-11/18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range                 (2019-11-09, 2019-11-18)\n",
       "best_score                           -0.123905\n",
       "random_score                         -0.176276\n",
       "model1_punish_0                      -0.136875\n",
       "model3_punish_1                      -0.123905\n",
       "model2_punish_0.6                    -0.123905\n",
       "model1_punish_0.03                   -0.123905\n",
       "model4_punish_0                      -0.138563\n",
       "Name: 14, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path_results['best_path_numeric'] = path_results['true_reward'].apply(lambda x: np.argsort(x)[-days_left:].sum())\n",
    "\n",
    "window_example_score = score_results.loc[14][['range','best_score','random_score','model1_punish_0',\\\n",
    "                      'model3_punish_1','model2_punish_0.6','model1_punish_0.03','model4_punish_0']]\n",
    "window_example_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, ('2019-11-09', '2019-11-18'))\n",
      "(1, [-0.11110701, -0.14222539, -0.20707455, -0.22597524, -0.11958275, -0.10108696, -0.14552328, -0.21551684, -0.26467669, -0.22998919])\n",
      "(2, ['2019-11-14', '2019-11-09', '2019-11-13', '2019-11-10', '2019-11-15'])\n",
      "(3, nan)\n",
      "(4, \"['2019-11-09', '2019-11-11', '2019-11-13', '2019-11-14', '2019-11-15']\")\n",
      "(5, \"['2019-11-09', '2019-11-10', '2019-11-13', '2019-11-14', '2019-11-15']\")\n",
      "(6, \"['2019-11-09', '2019-11-10', '2019-11-13', '2019-11-14', '2019-11-15']\")\n",
      "(7, \"['2019-11-09', '2019-11-10', '2019-11-13', '2019-11-14', '2019-11-15']\")\n",
      "(8, \"['2019-11-09', '2019-11-13', '2019-11-14', '2019-11-15', '2019-11-16']\")\n"
     ]
    }
   ],
   "source": [
    "window_example = path_results.loc[14][['range','true_reward','best_path','best_path_numeric','model1_punish_0',\\\n",
    "                      'model3_punish_1','model2_punish_0.6','model1_punish_0.03','model4_punish_0']]\n",
    "for i in enumerate(window_example):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare different punishment level within a model: how many times a (model, punish_level) hits to the best path among all different punishment levels given the same model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019-10-27', '2019-10-28', '2019-10-29', '2019-10-30', '2019-11-04']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(path_results[model1_cols].loc[0]['model1_punish_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range                 (2019-10-26, 2019-11-04, 2019-10-27, 2019-11-0...\n",
       "best_path             [2019-10-29, 2019-10-28, 2019-10-26, 2019-10-2...\n",
       "model1_punish_0                                                     124\n",
       "model1_punish_0.01                                                  122\n",
       "model1_punish_0.02                                                  122\n",
       "model1_punish_0.03                                                  122\n",
       "model1_punish_0.04                                                  121\n",
       "model1_punish_0.05                                                  118\n",
       "model1_punish_0.06                                                  115\n",
       "model1_punish_0.08                                                  112\n",
       "model1_punish_0.1                                                   108\n",
       "model1_punish_0.2                                                    85\n",
       "dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_cols = [col for col in score_results.columns if 'model1' in col]\n",
    "model1_cols.sort()\n",
    "\n",
    "best_model1 = path_results[['range','best_path']].copy()\n",
    "\n",
    "for col in model1_cols:\n",
    "    model_paths = path_results[col].apply(eval)\n",
    "    hit_best_counts = []\n",
    "    for modelpath, bestpath in zip(model_paths, path_results['best_path']):\n",
    "        hit_best_counts.append(len(set(modelpath)&set(bestpath)))\n",
    "    best_model1[col] = hit_best_counts\n",
    "    \n",
    "best_model1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range                (2019-10-26, 2019-11-04, 2019-10-27, 2019-11-0...\n",
       "best_path            [2019-10-29, 2019-10-28, 2019-10-26, 2019-10-2...\n",
       "model2_punish_0                                                    124\n",
       "model2_punish_0.2                                                  120\n",
       "model2_punish_0.4                                                  122\n",
       "model2_punish_0.6                                                  123\n",
       "model2_punish_0.8                                                  122\n",
       "model2_punish_1                                                    122\n",
       "model2_punish_10                                                    67\n",
       "model2_punish_2                                                    118\n",
       "model2_punish_5                                                     86\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_cols = [col for col in score_results.columns if 'model2' in col]\n",
    "model2_cols.sort()\n",
    "\n",
    "best_model2 = path_results[['range','best_path']].copy()\n",
    "\n",
    "for col in model2_cols:\n",
    "    model_paths = path_results[col].apply(eval)\n",
    "    hit_best_counts = []\n",
    "    for modelpath, bestpath in zip(model_paths, path_results['best_path']):\n",
    "        hit_best_counts.append(len(set(modelpath)&set(bestpath)))\n",
    "    best_model2[col] = hit_best_counts\n",
    "    \n",
    "best_model2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range                (2019-10-26, 2019-11-04, 2019-10-27, 2019-11-0...\n",
       "best_path            [2019-10-29, 2019-10-28, 2019-10-26, 2019-10-2...\n",
       "model3_punish_0                                                    124\n",
       "model3_punish_0.1                                                  120\n",
       "model3_punish_0.5                                                  122\n",
       "model3_punish_0.8                                                  121\n",
       "model3_punish_1                                                    122\n",
       "model3_punish_1.2                                                  120\n",
       "model3_punish_3                                                    104\n",
       "model3_punish_5                                                     95\n",
       "dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3_cols = [col for col in score_results.columns if 'model3' in col]\n",
    "model3_cols.sort()\n",
    "\n",
    "best_model3 = path_results[['range','best_path']].copy()\n",
    "\n",
    "for col in model3_cols:\n",
    "    model_paths = path_results[col].apply(eval)\n",
    "    hit_best_counts = []\n",
    "    for modelpath, bestpath in zip(model_paths, path_results['best_path']):\n",
    "        hit_best_counts.append(len(set(modelpath)&set(bestpath)))\n",
    "    best_model3[col] = hit_best_counts\n",
    "    \n",
    "best_model3.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare different models: \n",
    "\n",
    "MSE = mean((model_score - best_score)^2). The mean is taken across different (start_date, end_date) pairs.\n",
    "relative score = mean((model_score - random_score)/(best_score - random_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model3_punish_1       0.000015\n",
       "model2_punish_0.6     0.000016\n",
       "model1_punish_0.03    0.000017\n",
       "model2_punish_0.8     0.000017\n",
       "model2_punish_1       0.000018\n",
       "model1_punish_0.02    0.000019\n",
       "model1_punish_0.01    0.000019\n",
       "model2_punish_0.4     0.000019\n",
       "model3_punish_0.5     0.000019\n",
       "model3_punish_0.8     0.000020\n",
       "model1_punish_0.04    0.000021\n",
       "model1_punish_0       0.000028\n",
       "model2_punish_0       0.000028\n",
       "model3_punish_0       0.000028\n",
       "model3_punish_0.1     0.000031\n",
       "model2_punish_0.2     0.000032\n",
       "model1_punish_0.05    0.000042\n",
       "model3_punish_1.2     0.000047\n",
       "model2_punish_2       0.000075\n",
       "model1_punish_0.06    0.000085\n",
       "model1_punish_0.08    0.000123\n",
       "model1_punish_0.1     0.000195\n",
       "model4_punish_0       0.000240\n",
       "model3_punish_3       0.000289\n",
       "model3_punish_5       0.000530\n",
       "model2_punish_5       0.001644\n",
       "model1_punish_0.2     0.001717\n",
       "random_score          0.003107\n",
       "model2_punish_10      0.003978\n",
       "dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### MSE\n",
    "mse = {}\n",
    "### relative score\n",
    "relative = {}\n",
    "for col in score_results.columns[2:]:\n",
    "    mse[col] = ((score_results[col] - score_results['best_score'])**2).mean()\n",
    "    relative[col] = ((score_results[col] - score_results['random_score'])/(score_results['best_score'] - score_results['random_score'])).mean()\n",
    "\n",
    "mse = pd.Series(mse)\n",
    "relative = pd.Series(relative)\n",
    "mse.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model3_punish_1       0.957242\n",
       "model2_punish_0.6     0.955140\n",
       "model3_punish_0.5     0.954736\n",
       "model1_punish_0.03    0.952476\n",
       "model2_punish_0.8     0.951725\n",
       "model3_punish_0.8     0.951321\n",
       "model2_punish_0       0.950815\n",
       "model1_punish_0       0.950815\n",
       "model3_punish_0       0.950815\n",
       "model1_punish_0.01    0.950251\n",
       "model2_punish_0.4     0.950251\n",
       "model1_punish_0.02    0.950251\n",
       "model2_punish_1       0.947372\n",
       "model1_punish_0.04    0.944178\n",
       "model3_punish_0.1     0.936360\n",
       "model2_punish_0.2     0.933585\n",
       "model3_punish_1.2     0.931814\n",
       "model1_punish_0.05    0.912906\n",
       "model2_punish_2       0.905396\n",
       "model1_punish_0.06    0.871982\n",
       "model1_punish_0.08    0.836851\n",
       "model4_punish_0       0.816252\n",
       "model1_punish_0.1     0.797472\n",
       "model3_punish_3       0.760730\n",
       "model3_punish_5       0.659551\n",
       "model2_punish_5       0.440453\n",
       "model1_punish_0.2     0.438143\n",
       "model2_punish_10      0.123700\n",
       "random_score          0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
